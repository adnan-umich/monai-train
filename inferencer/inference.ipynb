{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29004eeb-2d7b-4a06-bd74-d4544e223605",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0eff8-352b-4f2d-9d75-fa5d2801aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    ResizeD,\n",
    "    LoadImage,\n",
    "    Rotate,\n",
    "    Randomizable,\n",
    "    Transform,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, ThreadDataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "from aim.pytorch import track_gradients_dists, track_params_dists\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5f9ea-86a0-4d64-a059-49d406db581d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test data inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "616bda97-5786-44d2-b992-fa1013f7aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root path to where the data is located\n",
    "DATA_DIR = \"\"\n",
    "MODEL_NAME = \"\" # Full path to model, including name. ex: /home/usr/model.pth\n",
    "\n",
    "# Automatically locates the 'imagesTs' folder\n",
    "test_images = sorted(glob.glob(os.path.join(DATA_DIR, \"imagesTs\", \"*.nii.gz\")))\n",
    "test_data = [{\"image\": image} for image in test_images]\n",
    "\n",
    "test_org_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=\"image\"),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\"], pixdim=(1.5, 1.5, 2.0), mode=\"bilinear\"),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "    ]\n",
    ")\n",
    "post_transforms = Compose(\n",
    "    [\n",
    "        Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=test_org_transforms,\n",
    "            orig_keys=\"image\",\n",
    "            meta_keys=\"pred_meta_dict\",\n",
    "            orig_meta_keys=\"image_meta_dict\",\n",
    "            meta_key_postfix=\"meta_dict\",\n",
    "            nearest_interp=False,\n",
    "            to_tensor=True,\n",
    "        ),\n",
    "        AsDiscreted(keys=\"pred\", argmax=True, to_onehot=2),\n",
    "        SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=\"./out\", output_postfix=\"seg\", resample=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Loads data into the data loader\n",
    "test_org_ds = Dataset(data=test_data, transform=test_org_transforms)\n",
    "test_org_loader = ThreadDataLoader(test_org_ds, batch_size=1, num_workers=0)\n",
    "loader = LoadImage()\n",
    "model.load_state_dict(torch.load(MODEL_NAME))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for test_data in test_org_loader:\n",
    "        test_inputs = test_data[\"image\"].to(device)\n",
    "        roi_size = 48 # Adjustable parameter to present overall image dimensions\n",
    "        sw_batch_size = 4\n",
    "        slice = 20 # Adjustable parameter (slice to visualize in the plots). Note inference is performed on the entire 3D dataset. \n",
    "        test_data[\"pred\"] = sliding_window_inference(test_inputs, roi_size, sw_batch_size, model)\n",
    "\n",
    "        test_data = [post_transforms(i) for i in decollate_batch(test_data)]\n",
    "\n",
    "        test_output = from_engine([\"pred\"])(test_data)\n",
    "\n",
    "        original_image = loader(test_output[0].meta[\"filename_or_obj\"])\n",
    "    \n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_image[:, :, slice], cmap=\"gray\")\n",
    "\n",
    "        mask_pred = np.zeros(original_image[:, :, slice].shape)\n",
    "        mask_pred[test_output[0].detach().cpu()[1, :, :, 20]==1] = 1\n",
    "        masked_pred = np.ma.masked_where(mask_pred == 0, mask_pred)\n",
    "        plt.imshow(masked_pred, 'Spectral', interpolation='none', alpha=0.7)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(test_output[0].detach().cpu()[1, :, :, slice])\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
